{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM-Based Product Match Verification - Project Walkthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides a complete walkthrough of the LLM-based product match verification system. It demonstrates:\n",
    "- How the project is structured\n",
    "- Needed env variables\n",
    "- How datasets are loaded and filtered\n",
    "- How LLM components are used\n",
    "- How the label verification is used\n",
    "- A look at the final results\n",
    "- Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "```src/\n",
    "src/\n",
    "    data_loading/\n",
    "        data_loader.py\n",
    "    llm/\n",
    "        client.py\n",
    "        prompt.py\n",
    "        label_verifier.py\n",
    "        llm_output_model.py\n",
    "    settings/\n",
    "        config.py\n",
    "project_walkthrough.ipynb\n",
    "README.MD\n",
    "requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture Overview\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "    A[DataLoader] --> B[Filtered DataFrame]\n",
    "    B --> C[LabelVerifier]\n",
    "    C --> D[LLMClient]\n",
    "    D --> E[OpenAI Responses API]\n",
    "    C --> F[LLMOutput]\n",
    "    F --> G[Final Results DataFrame]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The end-to-end running will be done in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing all Useful Classes and Configuration Strings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Classes for the end-to-end pipeline\n",
    "from data_loading.data_loader import DataLoader\n",
    "from llm.label_verifier import LabelVerifier\n",
    "from llm.client import LLMClient\n",
    "\n",
    "# Not needed to directly run end-to-end pipeline, but used in an example demonstration\n",
    "from llm.llm_output_model import LLMOutput\n",
    "\n",
    "# Configuration strings (used in the notebook for demonstration purposes)\n",
    "from llm.prompt import PROMPT\n",
    "from settings.config import DATA_PATH, OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Needed Enviornment Variables\n",
    "\n",
    "To run this project, a local .env file needs to be created with the env variables:\n",
    "- OPENAI_API_KEY: This will be the API key needed to configure the LLM Client\n",
    "- DATA_PATH: This is the path to the downloaded datasets \"shopping_queries_dataset_examples.parquet\" and \"shopping_queries_dataset_products.parquet\" from https://github.com/amazon-science/esci-data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DATA_PATH:\", bool(DATA_PATH))\n",
    "print(\"OPENAI_API_KEY loaded:\", bool(OPENAI_API_KEY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Filtering the Datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will load the 2 neccessary datasets using the data loader. This was designed to be a very re-usable class that is meant for our use case but flexible for other usages as well. It can:\n",
    "- load\n",
    "- merge\n",
    "- filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(\n",
    "    dataset_a_name=\"shopping_queries_dataset_examples.parquet\",\n",
    "    dataset_b_name=\"shopping_queries_dataset_products.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging & Filtering\n",
    "\n",
    "Our filtering method internally handles the merging and also allows us to filter based on an \"include\" condition and an \"equals\" condition. In our case, we will make sure the query is in the included queries of interest, and the ecsi label is equal to \"E\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing the columns to merge the two datasets on\n",
    "merge_columns = [\"product_id\", \"product_locale\"]\n",
    "\n",
    "# First filtering condition: Query\n",
    "include_col = \"query\"\n",
    "include_values = [\n",
    "    \"aa batteries 100 pack\",\n",
    "    \"kodak photo paper 8.5 x 11 glossy\",\n",
    "    \"dewalt 8v max cordless screwdriver kit, gyroscopic\"\n",
    "]\n",
    "\n",
    "# Second filtering condition: Label\n",
    "equal_col = 'esci_label'\n",
    "equal_values = 'E'\n",
    "\n",
    "# Use filtering method\n",
    "df_filtered = loader.create_filtered_dataset(\n",
    "    merge_on=merge_columns,\n",
    "    include_col=include_col, \n",
    "    include_values=include_values, \n",
    "    equal_col=equal_col, equal_value=equal_values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrating what the filtered data looks like\n",
    "\n",
    "df_filtered.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LLM Client is a wrapper around an azure call & returns a structured response in the form of a structured output.\n",
    "\n",
    "For structured outputs, we are using pydantic models to force the LLM to repond in a consistent schema (this simplifies downstream data processing).\n",
    "The model response has the following fields:\n",
    "- is_match_correct: a boolean that says whether the query matches the product\n",
    "- corrected_query: a string that contains the reformulated query if the match was incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = LLMClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prompt needs to validate whether the query and product match. In order to do so, it relies on some parameters from each unique query-match pair, particularly:\n",
    "- The query\n",
    "- Product information: Title, brand, description, and bullet points\n",
    "\n",
    "The prompt relies on a template and a structured output to make iteration easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(PROMPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example LLM Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_row = df_filtered.iloc[0]\n",
    "\n",
    "example_prompt = PROMPT.format(\n",
    "    query=example_row[\"query\"],\n",
    "    query_id=example_row[\"query_id\"],\n",
    "    product_id=example_row[\"product_id\"],\n",
    "    title=example_row[\"product_title\"],\n",
    "    brand=example_row[\"product_brand\"],\n",
    "    description=example_row[\"product_description\"],\n",
    "    bullets=example_row[\"product_bullet_point\"],\n",
    ")\n",
    "\n",
    "single_output = client.generate_structured_response(\n",
    "    prompt=example_prompt,\n",
    "    output_model=LLMOutput\n",
    ")\n",
    "\n",
    "print(\"Parsed Structured LLM Output (LLMOutput Model):\")\n",
    "single_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Verification\n",
    "\n",
    "This is the final crucial step of the pipeline. It runs the prompt on our particular filtered dataset, and returns a dataframe of the correct and incorrect matches.\n",
    "This class contains all LLM interaction logic in one place.\n",
    "It relies and handles interation between all the independent LLM components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verifier = LabelVerifier(llm_client=client)\n",
    "\n",
    "df_results = verifier.run_dataframe(df_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look a the final table with our results. Our end-to-end pipeline has been run to completion!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can see the results showing that most of our entries have a correct match between the query and the product. However, there are cases where a mix up has been made on some details, and the mismatches are shown. This gives us a powerful verification tool that could be generalized to other queues. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "\n",
    "This project follows a clean, modular architecture designed for clarity, maintainability, and correctness.\n",
    "\n",
    "#### Design Decisions\n",
    "- Modular Components:\n",
    "  - `DataLoader` handles loading and filtering only\n",
    "  - `LLMClient` abstracts all OpenAI interactions\n",
    "  - `LabelVerifier` orchestrates row-level processing and prompt formatting \n",
    "  - `LLMOutput` enforces a strict schema using Pydantic for reliable parsing\n",
    "\n",
    "- Structured LLM Output:\n",
    "  Using `responses.parse()` ensures consistent return types\n",
    "\n",
    "- Prompt Isolation:\n",
    "  The full prompt lives in `prompt.py`, making it easy to update and iterate independently from code\n",
    "\n",
    "- Declarative Filtering:\n",
    "  The DataLoader accepts flexible filter parameters (`include_col`, `equal_col`) instead of hard-coding logic\n",
    "\n",
    "### Summary\n",
    "This notebook shows the full end-to-end pipeline: loading data, preparing prompts, calling the LLM through a clean wrapper, parsing structured outputs, and producing final match decisions. The project is intentionally simple, readable, and production-friendlyâ€”making it easy for reviewers to run, inspect, and extend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hello2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "-1.-1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
